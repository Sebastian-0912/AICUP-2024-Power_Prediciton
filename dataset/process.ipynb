{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing libraries and loading the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_func(data):\n",
    "  # Convert 'DateTime' to datetime format\n",
    "  data['DateTime'] = pd.to_datetime(data['DateTime'])\n",
    "  \n",
    "  # Selecting numerical columns for normalization\n",
    "  normalize_features = ['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)']\n",
    "  data_numerical = data[normalize_features]\n",
    "\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  data_normalized = scaler.fit_transform(data_numerical)\n",
    "\n",
    "  # Creating a DataFrame with normalized data\n",
    "  data_normalized = pd.DataFrame(data_normalized, columns=normalize_features)\n",
    "\n",
    "  # Concatenate normalized data with other non-numerical columns if needed\n",
    "  data_normalized = pd.concat([data[['LocationCode', 'DateTime', 'Power(mW)','Hour',\n",
    "       'Minute', 'Month', 'Hour_sin', 'Hour_cos', 'Minute_sin', 'Minute_cos',\n",
    "       'Month_sin', 'Month_cos', 'DayOfYear', 'DayOfYear_sin',\n",
    "       'DayOfYear_cos']], data_normalized], axis=1)\n",
    "\n",
    "  return data_normalized\n",
    "  # print(data_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_filter_func(data:pd.DataFrame):\n",
    "  # Set DateTime as the index for resampling\n",
    "  data.set_index('DateTime', inplace=True)\n",
    "\n",
    "  # Resample data in 10-minute intervals using mean\n",
    "  # 'LocationCode' is a non-numeric column, so we need to handle it separately if we have multiple locations.\n",
    "  data_resampled = data.resample('10min').mean()\n",
    "\n",
    "  data_resampled = data_resampled.between_time(\"07:00\", \"16:50\")\n",
    "\n",
    "  # Reset index if you want DateTime as a regular column\n",
    "  data_resampled.reset_index(inplace=True)\n",
    "\n",
    "  data_resampled.dropna(inplace=True)\n",
    "\n",
    "  data_resampled['Date'] = data_resampled['DateTime'].dt.date\n",
    "  \n",
    "  data_resampled = data_resampled.groupby('Date').filter(lambda x: len(x)>=60)\n",
    "  \n",
    "  data_resampled = data_resampled.drop(columns=['Date'])\n",
    "  \n",
    "  return data_resampled\n",
    "\n",
    "  # print(data_resampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pipeline(data_path:str, save_path:str):\n",
    "  # Load the dataset (replace 'your_data.csv' with the actual file path)\n",
    "  data = pd.read_csv(data_path)\n",
    "  data_normalized = normalized_func(data)\n",
    "  data_resampled = resample_filter_func(data_normalized)\n",
    "  # Save the resampled data to a new CSV file\n",
    "  data_resampled.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_all(dataset_num:int):\n",
    "#   for step in range(1,dataset_num+1):\n",
    "#     data_path = f\"/home/sebastian/Desktop/AICUP-2024-Power_Prediciton/dataset/36_TrainingData_raw/L{step}_Train.csv\"\n",
    "#     save_path = f\"/home/sebastian/Desktop/AICUP-2024-Power_Prediciton/dataset/36_TrainingData_process/L{step}_Train_resampled.csv\"\n",
    "#     process_pipeline(data_path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all(dataset_num:int):\n",
    "  for step in range(1,dataset_num+1):\n",
    "    data_path = f\"/home/sebastian/Desktop/AICUP-2024-Power_Prediciton/dataset/36_TrainingData_interpolation/new_L{step}_Train.csv\"\n",
    "    save_path = f\"/home/sebastian/Desktop/AICUP-2024-Power_Prediciton/dataset/36_TrainingData_interpolation_process/L{step}_Train_resampled.csv\"\n",
    "    process_pipeline(data_path,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_all(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateTime', 'LocationCode', 'WindSpeed(m/s)', 'Pressure(hpa)',\n",
       "       'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)', 'Power(mW)', 'Hour',\n",
       "       'Minute', 'Month', 'Hour_sin', 'Hour_cos', 'Minute_sin', 'Minute_cos',\n",
       "       'Month_sin', 'Month_cos', 'DayOfYear', 'DayOfYear_sin',\n",
       "       'DayOfYear_cos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = f\"/home/sebastian/Desktop/AICUP-2024-Power_Prediciton/dataset/36_TrainingData_interpolation/new_L1_Train.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
